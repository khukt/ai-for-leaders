---
layout: default
title: "AI Regulation & Penalties"
nav_order: 3
---

# AI Regulation & Penalties

## The Regulatory Landscape Is Changing Fast

AI regulation is no longer a future concern. Laws are being enacted, enforcement actions are being taken, and organisations that have not prepared face real financial and reputational consequences.

Leaders need to understand the regulatory environment — not at the level of legal detail, but at the level of strategic exposure.

## Key Regulatory Frameworks

### EU AI Act

The EU AI Act is the world's first comprehensive AI regulation. It applies to any organisation that places AI systems on the EU market or uses AI systems affecting people in the EU — regardless of where the organisation is based.

The Act categorises AI systems by risk level:

| Risk Level | Examples | Requirements |
|---|---|---|
| **Unacceptable risk** | Social scoring, real-time biometric surveillance | Prohibited |
| **High risk** | Hiring tools, credit scoring, medical devices, law enforcement | Conformity assessment, transparency, human oversight |
| **Limited risk** | Chatbots, deepfakes | Transparency obligations |
| **Minimal risk** | Spam filters, AI in video games | No specific requirements |

**Penalties**: Up to €35 million or 7% of global annual turnover for the most serious violations.

### GDPR and AI

Many AI systems process personal data and are therefore subject to GDPR. Key implications include:
- Automated decision-making affecting individuals requires human oversight (Article 22)
- Data minimisation principles constrain training data collection
- Data subject rights (access, deletion, portability) extend to AI-derived insights

**Penalties**: Up to €20 million or 4% of global annual turnover.

### Sector-Specific Regulation

Many industries face additional AI-specific requirements:
- **Financial services**: Model risk management, explainability requirements
- **Healthcare**: Medical device regulation for diagnostic AI
- **Employment**: Anti-discrimination law applied to AI hiring tools

## What Leaders Should Know

1. **Territorial reach**: EU and US regulations can apply to organisations outside those jurisdictions if they affect citizens there.
2. **Third-party risk**: Using a vendor's AI system does not transfer regulatory liability. You remain responsible for how AI affects your customers and employees.
3. **Documentation**: Regulators increasingly require evidence that AI systems were tested, monitored, and governed. Lack of documentation is itself a risk.

## Key Questions for Leaders

- Which of our AI systems fall into regulated categories under applicable laws?
- Do we have documentation that would satisfy a regulatory audit?
- How do our vendor contracts address regulatory liability?

---

[← AI Landscape]({{ site.baseurl }}/book/01-ai-landscape/) | [Next: AI Strategy →]({{ site.baseurl }}/book/03-ai-strategy/)
